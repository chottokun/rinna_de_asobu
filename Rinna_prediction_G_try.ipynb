{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rinna_prediction_G_try.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNE1mX2DbVwq3uzI6/PUF3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "参考にさせていただいたサイト。ほぼそのままです。\n",
        "\n",
        "https://note.com/npaka/n/n8a435f0c8f69"
      ],
      "metadata": {
        "id": "FZr1Edkwfdg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2でファインチューニングしたモデルから文章生成する。\n",
        "\n",
        "公開されているRinnaの学習モデルをファインチューニングしたモデルから文章の生成を行う。\n",
        "\n",
        "環境\n",
        "\n",
        " - Clab PRO\n",
        " - Google Drive\n",
        "\n",
        "ディレクトリ\n",
        "\n",
        "./output : 学習したモデルを保存"
      ],
      "metadata": {
        "id": "uwaE-pyPfaxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Driveに接続\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p '/content/drive/My Drive/work/'\n",
        "%cd '/content/drive/My Drive/work/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApCCI8b1fjX_",
        "outputId": "c3fc5ea0-ed75-40ef-8be2-13c53becb097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9gfK5Xcfngy",
        "outputId": "aa2ede6b-121f-4ebd-8662-bc4dbab7fb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=9a6e11f7cb52bd86a25861b24245d2e08cc3ebdc5aebe72083135f087a47d4d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime 再起動"
      ],
      "metadata": {
        "id": "2kF7BqTKgOuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業フォルダへ\n",
        "%cd '/content/drive/My Drive/work/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfIgjpqWfrkm",
        "outputId": "ddf99877-2d03-483a-eb32-0b6c4127bb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Huggingface Datasetsのインストール\n",
        "!pip install datasets==1.2.1\n",
        "# Sentencepieceのインストール\n",
        "!pip install sentencepiece==0.1.91"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B8qH_7-fs9V",
        "outputId": "ebe549cb-e22c-4377-a882-baaf1fe6b1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==1.2.1\n",
            "  Downloading datasets-1.2.1-py3-none-any.whl (159 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51 kB 3.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 61 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 71 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 159 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.21.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.70.12.2)\n",
            "Collecting tqdm<4.50.0,>=4.27\n",
            "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.3.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (4.11.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.3.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2021.10.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.2.1) (1.15.0)\n",
            "Installing collected packages: xxhash, tqdm, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "Successfully installed datasets-1.2.1 tqdm-4.49.0 xxhash-3.0.0\n",
            "Collecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 3.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "「./transformers/examples/language-modeling/run_clm.py」の編集。\n",
        "「rinna」の日本語GPT-2モデルは「AutoTokenizer」ではなく「T5Tokenizer」を使う必要があります。"
      ],
      "metadata": {
        "id": "QUOeQKizf4a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, AutoModelForCausalLM\n",
        "import re\n",
        "\n",
        "# トークナイザーとモデルの準備\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-small\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"output/\")\n",
        "\n",
        "# テスト生成\n",
        "input = tokenizer.encode(\n",
        "    \"\"\"<s>アムロ：こんにちは</s>\n",
        "    <s>シャア：ララァはどこに行った？</s>\"\"\", return_tensors=\"pt\")\n",
        "output = model.generate(input,\n",
        "                        do_sample=True,\n",
        "                        top_p=0.90,\n",
        "                        top_k=0,\n",
        "                        max_length=200,\n",
        "                        skip_special_tokens=True,\n",
        "                        pad_token_id=tokenizer.pad_token_id,\n",
        "                        bos_token_id=tokenizer.bos_token_id,\n",
        "                        eos_token_id=tokenizer.eos_token_id,\n",
        "                        bad_word_ids=[[tokenizer.unk_token_id]],\n",
        "                        num_return_sequences=10\n",
        "                        )\n",
        "\n",
        "# 結果表示\n",
        "for list_output in output:\n",
        "  print(re.sub(r'<s>|<unk>|\\[PAD\\]|\\[SEP\\]| ', '',\n",
        "               tokenizer.decode(list_output).replace('</s>', '\\n')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wJ5QknBoZto",
        "outputId": "96fb9ea7-9c82-474b-ab70-0db9af53f189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:195: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "ハサウェイダミー\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロえず、落ちないはずだ\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロなぜ、シャアは地球を寒冷化するだけのエネルギーを使わないのか?\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロレーガン\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロそこかっ\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロ:ああ、地球連邦政府はジオンの残党狩りをしているのか\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "シャア:\"...えっ?\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロ:そこか?\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロサラダを一緒に食べるのは?\n",
            "\n",
            "アムロ:こんにちは\n",
            "シャア:ララァはどこに行った?\n",
            "アムロ:そこか?\n",
            "\n"
          ]
        }
      ]
    }
  ]
}